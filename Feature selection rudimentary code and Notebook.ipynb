{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eg002y4jaVnr"
   },
   "source": [
    "# Run the following two cells to install the necessary packages and compile the functions needed for feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pUghgXKmWNTX"
   },
   "source": [
    "## Dependencies and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_-E06tu_V0E3"
   },
   "outputs": [],
   "source": [
    "#Basic\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math \n",
    "\n",
    "#CV\n",
    "from sklearn.utils import safe_sqr\n",
    "from sklearn.base import clone\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#Feature Select\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import RFECV, RFE\n",
    "from boruta import BorutaPy\n",
    "\n",
    "#Models\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.linear_model import ElasticNetCV, ElasticNet\n",
    "from sklearn.linear_model import LassoCV, Lasso\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4r2_uwuWTMA"
   },
   "source": [
    "## Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sLWZuHoEWSVr"
   },
   "outputs": [],
   "source": [
    "def boruta(X, y):\n",
    "    name = 'Boruta de novo'\n",
    "    rf = RandomForestRegressor()\n",
    "    if len(X.columns) > 1500:\n",
    "        selector = BorutaPy(estimator = rf, n_estimators = 4, verbose=10).fit(np.array(X), np.array(y))\n",
    "        selected_cpgs = list(X.columns[selector.support_])   \n",
    "        return(name, selected_cpgs)\n",
    "    \n",
    "    elif len(X.columns) <= 1500:\n",
    "        selector = BorutaPy(estimator = rf, n_estimators = 'auto', verbose=10).fit(np.array(X), np.array(y))\n",
    "        selected_cpgs = list(X.columns[selector.support_])   \n",
    "        return(name, selected_cpgs)\n",
    "\n",
    "def preselected_with_boruta(X, y, selected_cpgs, name):\n",
    "    origin = name\n",
    "    X = X[selected_cpgs]\n",
    "    if len(X.columns) <= 0:\n",
    "        return(origin, [])\n",
    "    else:\n",
    "        name, new_cpgs = boruta(X,y)\n",
    "        return(origin, new_cpgs)\n",
    "\n",
    "def SFMElastic(X, y, X_test, y_test):\n",
    "    name = \"SFM Elastic de novo\"\n",
    "    thresh_list = [0.01, 0.05, 0.1, 0.5]\n",
    "    elas = ElasticNet()\n",
    "    best_score= 0\n",
    "    best_cpgs = []\n",
    "    \n",
    "    for i in thresh_list:\n",
    "        print(\"Completing SFM with threshold: \" +str(i))\n",
    "        selector = SelectFromModel(elas, threshold=i).fit(X, y)\n",
    "        feature_idx = selector.get_support(indices=True)\n",
    "        selected_cpgs = X.columns[feature_idx]\n",
    "        \n",
    "        if len(selected_cpgs) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            elas = ElasticNet()\n",
    "            elas.fit(X[selected_cpgs], y)\n",
    "            y_pred = elas.predict(X_test[selected_cpgs])\n",
    "            acc = (np.corrcoef(y_test, y_pred)[1][0])**2\n",
    "            if acc > best_score:\n",
    "                best_cpgs = selected_cpgs\n",
    "    return(name, best_cpgs)\n",
    "\n",
    "def SFMExtra(X, y, X_test, y_test):\n",
    "    name = \"SFM ExtraTrees de novo\"\n",
    "    thresh_list = [0.01, 0.05, 0.1, 0.5]\n",
    "    clf = ExtraTreesRegressor(n_estimators=8)\n",
    "    best_score= 0\n",
    "    best_cpgs = []\n",
    "    \n",
    "    for i in thresh_list:\n",
    "        print(\"Completing SFM with threshold: \" +str(i))\n",
    "        selector = SelectFromModel(clf, threshold=i).fit(X, y)\n",
    "        feature_idx = selector.get_support(indices=True)\n",
    "        selected_cpgs = X.columns[feature_idx]\n",
    "        \n",
    "        if len(selected_cpgs) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            elas = ElasticNet()\n",
    "            elas.fit(X[selected_cpgs], y)\n",
    "            y_pred = elas.predict(X_test[selected_cpgs])\n",
    "            acc = (np.corrcoef(y_test, y_pred)[1][0])**2\n",
    "            if acc > best_score:\n",
    "                best_cpgs = selected_cpgs\n",
    "    return(name, best_cpgs)\n",
    "        \n",
    "\n",
    "def RFE100(X, y, n_features_to_select = 100):\n",
    "    name = 'RFE de novo to 100'\n",
    "    elas = ElasticNet()\n",
    "    estimator = elas\n",
    "    n_features = X.shape[1]\n",
    "    n_features_to_select = n_features_to_select\n",
    "    support_ = np.ones(n_features, dtype=bool)\n",
    "    ranking_ = np.ones(n_features, dtype=int)\n",
    "    step = 0.01\n",
    "\n",
    "    while np.sum(support_) > n_features_to_select:\n",
    "        step = 0.01\n",
    "        features = np.arange(n_features)[support_]\n",
    "        estimator = clone(estimator)\n",
    "        print(\"Fitting estimator with %d features.\" % np.sum(support_))\n",
    "\n",
    "        estimator.fit(X.iloc[:,features], y)   \n",
    "        step = int(max(1, step * np.sum(support_)))\n",
    "        print(\"Eliminating \"+str(step)+ \" features\")\n",
    "\n",
    "        importances = estimator.coef_\n",
    "        if importances.ndim == 1:\n",
    "            importances = safe_sqr(importances)\n",
    "        else:\n",
    "            importances = safe_sqr(importances).sum(axis=0)\n",
    "\n",
    "        ranks = np.argsort(importances)\n",
    "        ranks = np.ravel(ranks)\n",
    "        threshold = min(step, np.sum(support_) - n_features_to_select)\n",
    "        support_[features[ranks][:threshold]] = False\n",
    "        ranking_[np.logical_not(support_)] += 1\n",
    "\n",
    "    features = np.arange(n_features)[support_]\n",
    "    estimator_ = clone(estimator)\n",
    "    final_model = estimator_.fit(X.iloc[:,features], y)\n",
    "\n",
    "    end_support = support_\n",
    "    end_ranking = ranking_\n",
    "    n_features_ = support_.sum()\n",
    "    feature_name = X.columns[end_support]\n",
    "    \n",
    "    selected_cpgs = list(feature_name)\n",
    "        \n",
    "    return(name, selected_cpgs)  \n",
    "\n",
    "def RFE1500(X, y, n_features_to_select = 1500):\n",
    "    name = 'RFE de novo to 1500'\n",
    "    elas = ElasticNet()\n",
    "    estimator = elas\n",
    "    n_features = X.shape[1]\n",
    "    n_features_to_select = n_features_to_select\n",
    "    support_ = np.ones(n_features, dtype=bool)\n",
    "    ranking_ = np.ones(n_features, dtype=int)\n",
    "    step = 0.01\n",
    "\n",
    "    while np.sum(support_) > n_features_to_select:\n",
    "        step = 0.01\n",
    "        features = np.arange(n_features)[support_]\n",
    "        estimator = clone(estimator)\n",
    "        print(\"Fitting estimator with %d features.\" % np.sum(support_))\n",
    "\n",
    "        estimator.fit(X.iloc[:,features], y)   \n",
    "        step = int(max(1, step * np.sum(support_)))\n",
    "        print(\"Eliminating \"+str(step)+ \" features\")\n",
    "\n",
    "        importances = estimator.coef_\n",
    "        if importances.ndim == 1:\n",
    "            importances = safe_sqr(importances)\n",
    "        else:\n",
    "            importances = safe_sqr(importances).sum(axis=0)\n",
    "\n",
    "        ranks = np.argsort(importances)\n",
    "        ranks = np.ravel(ranks)\n",
    "        threshold = min(step, np.sum(support_) - n_features_to_select)\n",
    "        support_[features[ranks][:threshold]] = False\n",
    "        ranking_[np.logical_not(support_)] += 1\n",
    "\n",
    "\n",
    "    features = np.arange(n_features)[support_]\n",
    "    estimator_ = clone(estimator)\n",
    "    final_model = estimator_.fit(X.iloc[:,features], y)\n",
    "\n",
    "    end_support = support_\n",
    "    end_ranking = ranking_\n",
    "    n_features_ = support_.sum()\n",
    "    feature_name = X.columns[end_support]\n",
    "    \n",
    "    selected_cpgs = list(feature_name)\n",
    "    return(selected_cpgs)  \n",
    "    \n",
    "def training_intersected_cpgs(X,y,score_dict):\n",
    "    name = 'Intersection of all selected CpGs'\n",
    "    all_cpgs = []\n",
    "    for name in score_dict.keys():\n",
    "        all_cpgs += list(score_dict[name][0])\n",
    "    all_cpgs = list(pd.Series(all_cpgs).dropna())\n",
    "    intersected_cpgs = list(set(all_cpgs))\n",
    "    return(name, intersected_cpgs)\n",
    "\n",
    "def RFE10k(X, y, n_features_to_select = 10000):\n",
    "    name = 'RFE de novo to 10000'\n",
    "    elas = ElasticNet()\n",
    "    estimator = elas\n",
    "    n_features = X.shape[1]\n",
    "    n_features_to_select = n_features_to_select\n",
    "    support_ = np.ones(n_features, dtype=bool)\n",
    "    ranking_ = np.ones(n_features, dtype=int)\n",
    "    step = 0.01\n",
    "\n",
    "    while np.sum(support_) > n_features_to_select:\n",
    "        step = 0.01\n",
    "        features = np.arange(n_features)[support_]\n",
    "        estimator = clone(estimator)\n",
    "        print(\"Fitting estimator with %d features.\" % np.sum(support_))\n",
    "\n",
    "        estimator.fit(X.iloc[:,features], y)   \n",
    "        step = int(max(1, step * np.sum(support_)))\n",
    "        print(\"Eliminating \"+str(step)+ \" features\")\n",
    "\n",
    "        importances = estimator.coef_\n",
    "        if importances.ndim == 1:\n",
    "            importances = safe_sqr(importances)\n",
    "        else:\n",
    "            importances = safe_sqr(importances).sum(axis=0)\n",
    "\n",
    "        ranks = np.argsort(importances)\n",
    "        ranks = np.ravel(ranks)\n",
    "        threshold = min(step, np.sum(support_) - n_features_to_select)\n",
    "        support_[features[ranks][:threshold]] = False\n",
    "        ranking_[np.logical_not(support_)] += 1\n",
    "\n",
    "\n",
    "    features = np.arange(n_features)[support_]\n",
    "    estimator_ = clone(estimator)\n",
    "    final_model = estimator_.fit(X.iloc[:,features], y)\n",
    "\n",
    "    end_support = support_\n",
    "    end_ranking = ranking_\n",
    "    n_features_ = support_.sum()\n",
    "    feature_name = X.columns[end_support]\n",
    "    \n",
    "    selected_cpgs = list(feature_name)\n",
    "    return(selected_cpgs) \n",
    "\n",
    "def creation(data): #Make no. of creatures, no. features etc. arguements\n",
    "    total_n_feat = len(data.columns)\n",
    "    n_feats_per_creat = 50\n",
    "    n_creatures = 3000 #int(n_feats_per_creat**3)\n",
    "    initial_dict = {}\n",
    "    for i in range(n_creatures):\n",
    "        creat_feat = random.sample(list(data.columns), n_feats_per_creat)\n",
    "        initial_dict[i] = [-999, creat_feat]\n",
    "\n",
    "    initial_population = pd.DataFrame(initial_dict)\n",
    "    initial_population = initial_population.transpose()\n",
    "    initial_population = initial_population.rename(columns={0: \"Score\", 1: \"Feat\"})\n",
    "    \n",
    "    return initial_population\n",
    "\n",
    "def training_creatures(X_train, y_train, X_test, y_test, initial_population):\n",
    "    \n",
    "    for i, r in initial_population.iterrows():\n",
    "        if initial_population.at[i, 'Score'] > 0 or math.isnan(initial_population.at[i, 'Score']):\n",
    "            continue\n",
    "        else:\n",
    "            cur_feat = r[1]\n",
    "            model = ElasticNet().fit(X_train[cur_feat],y_train)\n",
    "            y_pred = model.predict(X_test[cur_feat])\n",
    "            \n",
    "            acc = (np.corrcoef(y_test, y_pred)[1][0])**2\n",
    "            if math.isnan(acc) == True:\n",
    "                acc = 0.000000001\n",
    "                initial_population.at[i, 'Score'] = acc\n",
    "            else:\n",
    "                initial_population.at[i, 'Score'] = acc\n",
    "    return initial_population\n",
    "\n",
    "def cull_mate_mutate(data, cur_pop):\n",
    "    to_breed = len(cur_pop) - len(cur_pop.dropna())\n",
    "    cur_pop = cur_pop.dropna()\n",
    "    n_cull = int(0.50*len(cur_pop))\n",
    "    to_breed += n_cull\n",
    "    \n",
    "    cur_pop = cur_pop.sort_values(by=['Score'], ascending = False).iloc[:-n_cull, :]\n",
    "    cur_pop = cur_pop.reset_index().drop(['index'], axis=1)\n",
    "    fitness_list = list(cur_pop['Score'])\n",
    "    viable_parents = list(cur_pop.index)\n",
    "    \n",
    "    for i in range(to_breed):\n",
    "        cur_parents = random.choices(viable_parents, weights=np.array(fitness_list)/sum(fitness_list), k= 2)\n",
    "        while cur_parents[0] == cur_parents[1]:\n",
    "            cur_parents = random.choices(viable_parents, weights=np.array(fitness_list)/sum(fitness_list), k= 2)\n",
    "        parent1_genes = cur_pop.iloc[cur_parents[0]][1]\n",
    "        parent2_genes = cur_pop.iloc[cur_parents[1]][1]\n",
    "        set_parents_genes = list(set(list(parent1_genes) + list(parent2_genes)))\n",
    "        child_genes = list(random.sample(set_parents_genes, len(parent1_genes)))\n",
    "\n",
    "        if random.randrange(0,100,1)/100 < 0.2:\n",
    "            non_mutant_genes = list(random.sample(child_genes, int(0.7*len(child_genes))))\n",
    "            possible_mutants = set(data.columns) - set(non_mutant_genes)\n",
    "            mutant_genes = list(random.sample(possible_mutants, len(parent1_genes) - len(non_mutant_genes)))\n",
    "            child_genes = mutant_genes + non_mutant_genes\n",
    "            \n",
    "            child = {'Score': -999, 'Feat': child_genes}\n",
    "            cur_pop = cur_pop.append(child, ignore_index = True)\n",
    "            \n",
    "        else:\n",
    "            child = {'Score': -999, 'Feat': child_genes}\n",
    "            cur_pop = cur_pop.append(child, ignore_index = True)\n",
    "        \n",
    "    return cur_pop\n",
    "\n",
    "def ga(X_train, y_train, X_test, y_test):\n",
    "    cur_creatures = creation(X_train)\n",
    "    fitness = max(cur_creatures['Score'])\n",
    "    generation = 0\n",
    "    while generation < 100:\n",
    "        cur_trained = training_creatures(X_train, y_train, X_test, y_test, cur_creatures)\n",
    "        cur_creatures = cull_mate_mutate(X_train, cur_trained)\n",
    "        fitness = max(cur_creatures['Score'])\n",
    "        generation += 1\n",
    "        print('Generation ' + str(generation), fitness)\n",
    "\n",
    "    best_acc = 0\n",
    "    best_cpgs = []\n",
    "    for i in range(10):\n",
    "\n",
    "        elas = ElasticNet()\n",
    "        param_grid = {\"max_iter\": [100, 500, 1000],\n",
    "                  \"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                  \"l1_ratio\": np.arange(0.0, 1.0, 0.1)}\n",
    "\n",
    "        grid = GridSearchCV(estimator=elas,\n",
    "                             param_grid=param_grid,\n",
    "                             scoring='r2',\n",
    "                             cv=10,\n",
    "                             n_jobs=-1)\n",
    "        grid.fit(X_train[cur_creatures['Feat'][i]].to_numpy(), y_train)\n",
    "        best_parameters = grid.best_params_\n",
    "\n",
    "        final_clock_model = ElasticNet(alpha = best_parameters['alpha'], l1_ratio = best_parameters['l1_ratio'], max_iter = best_parameters['max_iter'])\n",
    "        final_clock_model.fit(X_train[cur_creatures['Feat'][i]].to_numpy(), y_train)\n",
    "        y_pred = final_clock_model.predict(X_test[cur_creatures['Feat'][i]].to_numpy())\n",
    "\n",
    "        acc = (np.corrcoef(y_test, y_pred)[1][0])**2\n",
    "        if acc > best_acc:\n",
    "            best_cpgs = cur_creatures['Feat'][i]\n",
    "\n",
    "    return best_cpgs\n",
    "\n",
    "def feature_selection(filepath):\n",
    "    input_data = pd.read_csv(filepath)\n",
    "    X = input_data.drop(['Age'], axis = 1)\n",
    "    y = input_data['Age']\n",
    "\n",
    "    boruta_list = []\n",
    "    rfe1500_to_boruta = []\n",
    "    rfe100 = []\n",
    "    sfm_elas = []\n",
    "    sfm_elas_boruta = []\n",
    "    sfm_extra = []\n",
    "    sfm_extra_boruta = []\n",
    "    rfe1500_to_sfm = []\n",
    "    rfe1000_to_rfecv = []\n",
    "    Kbest_list_25 = []\n",
    "    Kbest_list_2000_boruta = []\n",
    "    basic_elas_list = []\n",
    "    rfe10k_ga_list = []\n",
    "    ga_list = []\n",
    "    inter = []\n",
    "    inter_boruta =[]\n",
    "\n",
    "    cv = KFold(n_splits = 5, shuffle = True, random_state = 0)\n",
    "    counter = 1\n",
    "    for train_indices, test_indices in cv.split(X):\n",
    "        score_dict = {}\n",
    "        X_train = X_df.loc[train_indices, :]\n",
    "        X_test = X_df.loc[test_indices, :]\n",
    "        y_train, y_test = y[train_indices], y[test_indices]\n",
    "\n",
    "        boruta_name, boruta_selected_cpgs = boruta(X_train,y_train)\n",
    "        score_dict[boruta_name] = [boruta_selected_cpgs]\n",
    "        boruta_list += list(boruta_selected_cpgs)\n",
    "        if counter == 1:\n",
    "            boruta_intersect = boruta_selected_cpgs\n",
    "        else: \n",
    "            boruta_intersect = list(set(boruta_intersect) & set(boruta_selected_cpgs))\n",
    "        #_____________________________________________________________________________________________________________________________________\n",
    "\n",
    "        rfe_1500_cpgs = RFE1500(X_train, y_train)\n",
    "        rfe_1000_cpgs = RFE1500(X_train[rfe_1500_cpgs],y_train, 1000) #Use the 1500 before to go to 1000\n",
    "\n",
    "        elas = ElasticNet()\n",
    "        selector = RFECV(estimator = elas, step=1, cv = 10, scoring = 'r2').fit(X_train[rfe_1000_cpgs], y_train)\n",
    "        feature_idx = selector.get_support(indices=True)\n",
    "        rfe_1000_to_rfecv_cpgs = list(X_train[rfe_1000_cpgs].columns[feature_idx])\n",
    "        score_dict['RFE de novo to 1000 followed by RFECV'] = [rfe_1000_to_rfecv_cpgs]\n",
    "        rfe1000_to_rfecv += list(rfe_1000_to_rfecv_cpgs)\n",
    "        if counter == 1:\n",
    "            rfe1000_to_rfecv_intersect = rfe_1000_to_rfecv_cpgs\n",
    "        else: \n",
    "            rfe1000_to_rfecv_intersect = list(set(rfe1000_to_rfecv_intersect) & set(rfe_1000_to_rfecv_cpgs))\n",
    "\n",
    "        rfe_w_boruta_name, rfe_w_boruta_selected_cpgs = preselected_with_boruta(X_train, y_train, rfe_1500_cpgs, 'RFE de novo to 1500 followed by Boruta')\n",
    "        score_dict[rfe_w_boruta_name] = [rfe_w_boruta_selected_cpgs]\n",
    "        rfe1500_to_boruta += list(rfe_w_boruta_selected_cpgs)\n",
    "        if counter == 1:\n",
    "            rfe1500_to_boruta_intersect = rfe_w_boruta_selected_cpgs\n",
    "        else: \n",
    "            rfe1500_to_boruta_intersect = list(set(rfe1500_to_boruta_intersect) & set(rfe_w_boruta_selected_cpgs))\n",
    "\n",
    "        rfe_name, rfe_selected_cpgs = RFE100(X_train[rfe_1000_cpgs],y_train)\n",
    "        score_dict[rfe_name] = [rfe_selected_cpgs]\n",
    "        rfe100 += list(rfe_selected_cpgs)\n",
    "        if counter == 1:\n",
    "            rfe100_intersect = rfe_selected_cpgs\n",
    "        else: \n",
    "            rfe100_intersect = list(set(rfe100_intersect) & set(rfe_selected_cpgs))\n",
    "        #_____________________________________________________________________________________________________________________________________\n",
    "\n",
    "        sfm_elas_name, sfm_elas_selected_cpgs = SFMElastic(X_train, y_train, X_test, y_test)\n",
    "        score_dict[sfm_elas_name] = [sfm_elas_selected_cpgs]\n",
    "        sfm_elas += list(sfm_elas_selected_cpgs)\n",
    "        if counter == 1:\n",
    "            sfm_elas_intersect = sfm_elas_selected_cpgs\n",
    "        else: \n",
    "            sfm_elas_intersect = list(set(sfm_elas_intersect) & set(sfm_elas_selected_cpgs))\n",
    "\n",
    "        sfm_elas_w_boruta_name, sfm_elas_w_boruta_selected_cpgs = preselected_with_boruta(X_train, y_train, sfm_elas_selected_cpgs, 'SFMElastic de novo followed by Boruta')\n",
    "        score_dict[sfm_elas_w_boruta_name] = [sfm_elas_w_boruta_selected_cpgs]\n",
    "        sfm_elas_boruta += list(sfm_elas_w_boruta_selected_cpgs)\n",
    "\n",
    "        if counter == 1:\n",
    "            sfm_elas_boruta_intersect = sfm_elas_w_boruta_selected_cpgs\n",
    "        else: \n",
    "            sfm_elas_boruta_intersect = list(set(sfm_elas_boruta_intersect) & set(sfm_elas_w_boruta_selected_cpgs))\n",
    "        #_____\n",
    "\n",
    "        sfm_extra_name, sfm_extra_selected_cpgs = SFMExtra(X_train, y_train, X_test, y_test)\n",
    "        score_dict[sfm_extra_name] = [sfm_extra_selected_cpgs]\n",
    "        sfm_extra += list(sfm_extra_selected_cpgs)\n",
    "        if counter == 1:\n",
    "            sfm_extra_intersect = sfm_extra_selected_cpgs\n",
    "        else: \n",
    "            sfm_extra_intersect = list(set(sfm_extra_intersect) & set(sfm_extra_selected_cpgs))\n",
    "\n",
    "        sfm_extra_w_boruta_name, sfm_extra_w_boruta_selected_cpgs = preselected_with_boruta(X_train, y_train, sfm_extra_selected_cpgs, 'SFMExtra de novo followed by Boruta')\n",
    "        score_dict[sfm_extra_w_boruta_name] = [sfm_extra_w_boruta_selected_cpgs]\n",
    "        sfm_extra_boruta += list(sfm_extra_w_boruta_selected_cpgs)\n",
    "        if counter == 1:\n",
    "            sfm_extra_boruta_intersect = sfm_extra_w_boruta_selected_cpgs\n",
    "        else: \n",
    "            sfm_extra_boruta_intersect = list(set(sfm_extra_boruta_intersect) & set(sfm_extra_w_boruta_selected_cpgs))\n",
    "\n",
    "        rfe_1500_to_sfm_name, rfe_1500_to_sfm_selected_cpgs = SFMElastic(X_train[rfe_1500_cpgs], y_train, X_test, y_test)\n",
    "        score_dict['RFE de novo to 1500 followed by SFM'] = [rfe_1500_to_sfm_selected_cpgs] #might need to turn into a list\n",
    "        rfe1500_to_sfm += list(rfe_1500_to_sfm_selected_cpgs)\n",
    "        if counter == 1:\n",
    "            rfe1500_to_sfm_intersect = rfe_1500_to_sfm_selected_cpgs\n",
    "        else: \n",
    "            rfe1500_to_sfm_intersect = list(set(rfe1500_to_sfm_intersect) & set(rfe_1500_to_sfm_selected_cpgs))\n",
    "        #_____________________________________________________________________________________________________________________________________\n",
    "\n",
    "        selector = SelectKBest(score_func=f_regression, k=25).fit(X_train, y_train)\n",
    "        feature_idx = selector.get_support(indices=True)\n",
    "        selected_cpgs_25 = X_train.columns[feature_idx]\n",
    "        score_dict['KBest 25'] = [selected_cpgs_25]\n",
    "        Kbest_list_25 += list(selected_cpgs_25)\n",
    "        if counter == 1:\n",
    "            Kbest_list_25_intersect = selected_cpgs_25\n",
    "        else: \n",
    "            Kbest_list_25_intersect = list(set(Kbest_list_25_intersect) & set(selected_cpgs_25))\n",
    "\n",
    "\n",
    "        selector = SelectKBest(score_func=f_regression, k=2000).fit(X_train, y_train)\n",
    "        feature_idx = selector.get_support(indices=True)\n",
    "        selected_cpgs_2000 = X_train.columns[feature_idx]\n",
    "        Kbest_name, Kbest_boruta_cpgs = preselected_with_boruta(X_train, y_train, selected_cpgs_2000, 'KBest de novo followed by Boruta')\n",
    "        score_dict['KBest 2000 then Boruta'] = [Kbest_boruta_cpgs]\n",
    "        Kbest_list_2000_boruta += list(Kbest_boruta_cpgs)\n",
    "        if counter == 1:\n",
    "            Kbest_list_2000_boruta_intersect = Kbest_boruta_cpgs\n",
    "        else: \n",
    "            Kbest_list_2000_boruta_intersect = list(set(Kbest_list_2000_boruta_intersect) & set(Kbest_boruta_cpgs))\n",
    "\n",
    "        basic_elas = ElasticNet().fit(X_train, y_train)\n",
    "        coef = pd.DataFrame(basic_elas.coef_, index = X_train.columns)\n",
    "        coef = coef.reset_index()\n",
    "        basic_elas_cpgs = list(coef[coef[0] != 0].iloc[:,0])\n",
    "        score_dict['Basic ElasticNet'] = [basic_elas_cpgs]\n",
    "        basic_elas_list += list(basic_elas_cpgs)\n",
    "        if counter == 1:\n",
    "            basic_elas_intersect = basic_elas_cpgs\n",
    "        else: \n",
    "            basic_elas_intersect = list(set(basic_elas_intersect) & set(basic_elas_cpgs))\n",
    "\n",
    "\n",
    "        rfe_10k_cpgs = RFE10k(X_train, y_train)\n",
    "        rfe10k_ga_cpgs = ga(X_train[rfe_10k_cpgs], y_train, X_test[rfe_10k_cpgs], y_test)\n",
    "        score_dict['RFE10K then GA'] = [rfe10k_ga_cpgs]\n",
    "        rfe10k_ga_list += list(rfe10k_ga_cpgs)\n",
    "        if counter == 1:\n",
    "            rfe10k_ga_intersect = rfe10k_ga_cpgs\n",
    "        else: \n",
    "            rfe10k_ga_intersect = list(set(rfe10k_ga_intersect) & set(rfe10k_ga_cpgs))\n",
    "\n",
    "\n",
    "        ga_cpgs = ga(X_train, y_train, X_test, y_test)\n",
    "        score_dict['GA de novo'] = [ga_cpgs]\n",
    "        ga_list += list(ga_cpgs)\n",
    "        if counter == 1:\n",
    "            ga_intersect = ga_cpgs\n",
    "        else: \n",
    "            ga_intersect = list(set(ga_intersect) & set(ga_cpgs))\n",
    "\n",
    "        #_____________________________________________________________________________________________________________________________________\n",
    "\n",
    "        inter_name, inter_selected_cpgs = training_intersected_cpgs(X_train, y_train, score_dict)    \n",
    "        score_dict[inter_name] = [inter_selected_cpgs]\n",
    "        inter += list(inter_selected_cpgs)\n",
    "        if counter == 1:\n",
    "            inter_intersect = inter_selected_cpgs\n",
    "        else: \n",
    "            inter_intersect = list(set(inter_intersect) & set(inter_selected_cpgs))\n",
    "\n",
    "        inter_w_boruta_name, inter_w_boruta_selected_cpgs = preselected_with_boruta(X_train, y_train, inter_selected_cpgs, 'Intersection followed by Boruta')\n",
    "        score_dict[inter_w_boruta_name] = [inter_w_boruta_selected_cpgs]\n",
    "        inter_boruta += list(inter_w_boruta_selected_cpgs)\n",
    "        if counter == 1:\n",
    "            inter_boruta_intersect = inter_w_boruta_selected_cpgs\n",
    "        else: \n",
    "            inter_boruta_intersect = list(set(inter_boruta_intersect) & set(inter_w_boruta_selected_cpgs))\n",
    "        #_____________________________________________________________________________________________________________________________________\n",
    "\n",
    "        counter+=1\n",
    "\n",
    "\n",
    "    d = {'boruta': list(boruta_list), \n",
    "         'rfe1500_to_boruta': list(rfe1500_to_boruta),\n",
    "         'rfe_1000_to_rfecv_cpgs': list(rfe1000_to_rfecv),\n",
    "         'rfe100' : list(rfe100),\n",
    "         'sfm_elas': list(sfm_elas),\n",
    "         'sfm_elas_boruta': list(sfm_elas_boruta),\n",
    "         'sfm_extra': list(sfm_extra),\n",
    "         'sfm_extra_boruta': list(sfm_extra_boruta),\n",
    "         'rfe1500_to_sfm': list(rfe1500_to_sfm),\n",
    "         'kbest25': list(Kbest_list_25),\n",
    "         'kbest2k_boruta': list(Kbest_list_2000_boruta),\n",
    "         'basic_elas': list(basic_elas_list),\n",
    "         'ga': list(ga_list),\n",
    "         'rfe10k_ga_list' : list(rfe10k_ga_list),\n",
    "         'inter': list(inter),\n",
    "         'inter_boruta': list(inter_boruta)}\n",
    "\n",
    "    final_cpgs_df = pd.DataFrame()\n",
    "    name_list = []\n",
    "    for method in d.keys():\n",
    "        cur_cpg_list = pd.Series(d[method])\n",
    "        name_list.append(method)\n",
    "        final_cpgs_df = pd.concat([final_cpgs_df, cur_cpg_list], ignore_index=True, axis=1)\n",
    "    final_cpgs_df.to_csv('results.csv',index=False)\n",
    "    print('Finished')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZMbIQXhNZXGr"
   },
   "source": [
    "# Run the main function below by entering the filepath as an argument.\n",
    "\n",
    "Example: feature_selection('methylation_data.csv')\n",
    "\n",
    "The feature selection and clock building will begin. This can take a while. You will see the results and 'Finished' at in the output cell once it is finished.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L66b3uSwbxJx"
   },
   "outputs": [],
   "source": [
    "feature_selection(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "58wqiCxRc5IY"
   },
   "source": [
    "# Results\n",
    "\n",
    "After the results are finished, you can run the following code to view the CpGs selected and their correlation with one another with Age Labels. You can also view visualizations of the clock's performance. \n",
    "\n",
    "Otherwise, the process is finished and you should have a new files created in the directory: \n",
    "\n",
    "'results.csv' : Contains each set of CpGs selected with the name of the method used as columns  and the performance estimate it achieved as the header. The user can use this to see which CpGs are of importance and worth studying.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AGwaAV0acPkj"
   },
   "source": [
    "The columns of this csv file will correspond to the total features selected by that method. i.e. the combination of every feature selected at each of the 5 folds of CV. From this point, you're free to choose which column (set of features) you'd like to reduce your original dataset down to and create a clock from. \n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "pUghgXKmWNTX",
    "ZMbIQXhNZXGr"
   ],
   "name": "CLK_MKR.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
